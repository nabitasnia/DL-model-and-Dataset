{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4du2N4gXQMs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main architecture of the model\n",
        "\n",
        "loading the training dataset"
      ],
      "metadata": {
        "id": "tfgKjquVXRkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df5= pd.read_csv('TNF-alpha_06_bioactivity_data_3class_pIC50_pubchem_fp.csv')\n",
        "df5"
      ],
      "metadata": {
        "id": "YRHvWf55XUwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df5.iloc[:,:-1]\n",
        "X"
      ],
      "metadata": {
        "id": "mW-6AX2oXhm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variance thresholding on the training dataset"
      ],
      "metadata": {
        "id": "MqU7vravXlkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# Extract the feature names from the DataFrame\n",
        "feature_names = X.columns\n",
        "\n",
        "# Convert the DataFrame to a numpy array\n",
        "X2 = X.values\n",
        "\n",
        "# Apply VarianceThreshold\n",
        "selection = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
        "X2_selected = selection.fit_transform(X2)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_indices = selection.get_support(indices=True)\n",
        "\n",
        "# Get the corresponding feature names\n",
        "selected_feature_names = feature_names[selected_indices]\n",
        "\n",
        "# Convert the transformed array back to DataFrame\n",
        "X_selected = pd.DataFrame(X2_selected, columns=selected_feature_names)\n",
        "X_selected"
      ],
      "metadata": {
        "id": "xSgGP1xlXoZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading the testing dataset which was produced using padelpy(pubchem Fingerprint) Codes are mentioned above"
      ],
      "metadata": {
        "id": "O_pkEXdiXsdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df4= pd.read_csv('Testing_compounds_set.csv')\n",
        "df4"
      ],
      "metadata": {
        "id": "JVAyYtRxXupA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the first column of the descriptors dataset\n",
        "first_column = df4.iloc[:, 0]\n",
        "first_column"
      ],
      "metadata": {
        "id": "yw9Rf3AZXzww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = df4.iloc[:, 1:]\n",
        "df4"
      ],
      "metadata": {
        "id": "CnYmI16wX2PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "variance thresholding on the testing dataset"
      ],
      "metadata": {
        "id": "tgl-lNrWX5CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the feature names from the DataFrame\n",
        "feature_names = df4.columns\n",
        "\n",
        "# Convert the DataFrame to a numpy array\n",
        "X6 = df4.values\n",
        "\n",
        "# Apply VarianceThreshold\n",
        "selection = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
        "X6_selected = selection.fit_transform(X6)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_indices = selection.get_support(indices=True)\n",
        "\n",
        "# Get the corresponding feature names\n",
        "selected_feature_names2 = feature_names[selected_indices]\n",
        "\n",
        "# Convert the transformed array back to DataFrame\n",
        "X6_selected = pd.DataFrame(X6_selected, columns=selected_feature_names2)\n",
        "X6_selected"
      ],
      "metadata": {
        "id": "zGWwC0g9X5x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names_list = X_selected.columns.tolist()\n",
        "\n",
        "print(column_names_list)"
      ],
      "metadata": {
        "id": "RBqHTmoyX_Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names_list = X6_selected.columns.tolist()\n",
        "\n",
        "print(column_names_list)"
      ],
      "metadata": {
        "id": "ok_Jdw8TYETx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataset is stored in a DataFrame called 'X'\n",
        "column_names= ['PubchemFP1', 'PubchemFP2', 'PubchemFP3', 'PubchemFP11', 'PubchemFP12', 'PubchemFP13', 'PubchemFP14', 'PubchemFP15', 'PubchemFP16', 'PubchemFP19', 'PubchemFP20', 'PubchemFP21', 'PubchemFP143', 'PubchemFP144', 'PubchemFP145', 'PubchemFP146', 'PubchemFP150', 'PubchemFP178', 'PubchemFP179', 'PubchemFP180', 'PubchemFP181', 'PubchemFP182', 'PubchemFP184', 'PubchemFP185', 'PubchemFP186', 'PubchemFP188', 'PubchemFP192', 'PubchemFP193', 'PubchemFP199', 'PubchemFP255', 'PubchemFP256', 'PubchemFP257', 'PubchemFP285', 'PubchemFP299', 'PubchemFP308', 'PubchemFP333', 'PubchemFP334', 'PubchemFP335', 'PubchemFP337', 'PubchemFP338', 'PubchemFP339', 'PubchemFP340', 'PubchemFP341', 'PubchemFP345', 'PubchemFP346', 'PubchemFP347', 'PubchemFP351', 'PubchemFP355', 'PubchemFP356', 'PubchemFP357', 'PubchemFP358', 'PubchemFP365', 'PubchemFP366', 'PubchemFP367', 'PubchemFP370', 'PubchemFP371', 'PubchemFP373', 'PubchemFP374', 'PubchemFP375', 'PubchemFP376', 'PubchemFP377', 'PubchemFP380', 'PubchemFP381', 'PubchemFP382', 'PubchemFP384', 'PubchemFP387', 'PubchemFP390', 'PubchemFP391', 'PubchemFP392', 'PubchemFP393', 'PubchemFP396', 'PubchemFP403', 'PubchemFP405', 'PubchemFP406', 'PubchemFP416', 'PubchemFP418', 'PubchemFP420', 'PubchemFP430', 'PubchemFP431', 'PubchemFP432', 'PubchemFP434', 'PubchemFP437', 'PubchemFP439', 'PubchemFP440', 'PubchemFP441', 'PubchemFP442', 'PubchemFP443', 'PubchemFP446', 'PubchemFP447', 'PubchemFP449', 'PubchemFP450', 'PubchemFP451', 'PubchemFP452', 'PubchemFP453', 'PubchemFP462', 'PubchemFP464', 'PubchemFP470', 'PubchemFP472', 'PubchemFP476', 'PubchemFP482', 'PubchemFP490', 'PubchemFP491', 'PubchemFP493', 'PubchemFP495', 'PubchemFP498', 'PubchemFP502', 'PubchemFP506', 'PubchemFP516', 'PubchemFP520', 'PubchemFP521', 'PubchemFP523', 'PubchemFP524', 'PubchemFP528', 'PubchemFP530', 'PubchemFP535', 'PubchemFP536', 'PubchemFP537', 'PubchemFP538', 'PubchemFP539', 'PubchemFP540', 'PubchemFP541', 'PubchemFP542', 'PubchemFP544', 'PubchemFP545', 'PubchemFP546', 'PubchemFP548', 'PubchemFP549', 'PubchemFP552', 'PubchemFP553', 'PubchemFP555', 'PubchemFP556', 'PubchemFP563', 'PubchemFP564', 'PubchemFP565', 'PubchemFP566', 'PubchemFP567', 'PubchemFP569', 'PubchemFP570', 'PubchemFP571', 'PubchemFP573', 'PubchemFP574', 'PubchemFP575', 'PubchemFP578', 'PubchemFP579', 'PubchemFP580', 'PubchemFP581', 'PubchemFP582', 'PubchemFP584', 'PubchemFP585', 'PubchemFP589', 'PubchemFP590', 'PubchemFP592', 'PubchemFP593', 'PubchemFP594', 'PubchemFP595', 'PubchemFP597', 'PubchemFP599', 'PubchemFP600', 'PubchemFP602', 'PubchemFP603', 'PubchemFP604', 'PubchemFP606', 'PubchemFP607', 'PubchemFP608', 'PubchemFP610', 'PubchemFP611', 'PubchemFP613', 'PubchemFP614', 'PubchemFP617', 'PubchemFP618', 'PubchemFP619', 'PubchemFP620', 'PubchemFP623', 'PubchemFP625', 'PubchemFP626', 'PubchemFP628', 'PubchemFP630', 'PubchemFP631', 'PubchemFP632', 'PubchemFP633', 'PubchemFP634', 'PubchemFP637', 'PubchemFP638', 'PubchemFP639', 'PubchemFP640', 'PubchemFP641', 'PubchemFP642', 'PubchemFP643', 'PubchemFP645', 'PubchemFP646', 'PubchemFP651', 'PubchemFP653', 'PubchemFP655', 'PubchemFP656', 'PubchemFP657', 'PubchemFP659', 'PubchemFP660', 'PubchemFP661', 'PubchemFP662', 'PubchemFP663', 'PubchemFP664', 'PubchemFP665', 'PubchemFP666', 'PubchemFP667', 'PubchemFP668', 'PubchemFP671', 'PubchemFP672', 'PubchemFP677', 'PubchemFP678', 'PubchemFP679', 'PubchemFP680', 'PubchemFP681', 'PubchemFP682', 'PubchemFP683', 'PubchemFP684', 'PubchemFP686', 'PubchemFP688', 'PubchemFP689', 'PubchemFP690', 'PubchemFP691', 'PubchemFP692', 'PubchemFP693', 'PubchemFP696', 'PubchemFP697', 'PubchemFP698', 'PubchemFP699', 'PubchemFP700', 'PubchemFP701', 'PubchemFP702', 'PubchemFP704', 'PubchemFP705', 'PubchemFP708', 'PubchemFP709', 'PubchemFP710', 'PubchemFP711', 'PubchemFP712', 'PubchemFP714', 'PubchemFP735', 'PubchemFP740', 'PubchemFP755', 'PubchemFP756', 'PubchemFP761', 'PubchemFP776', 'PubchemFP777', 'PubchemFP797', 'PubchemFP798', 'PubchemFP803', 'PubchemFP818', 'PubchemFP819', 'PubchemFP824', 'PubchemFP860']\n",
        "#filtered_df = X[column_names]\n",
        "\n",
        "# Alternatively, you can use the .loc accessor to filter the columns\n",
        "filtered_df = X.loc[:, column_names]\n",
        "\n",
        "# Print the filtered dataset\n",
        "filtered_df"
      ],
      "metadata": {
        "id": "3a5mv4ZJYE9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataset is stored in a DataFrame called 'X'\n",
        "column_names=['PubchemFP2', 'PubchemFP12', 'PubchemFP16', 'PubchemFP19', 'PubchemFP20', 'PubchemFP23', 'PubchemFP33', 'PubchemFP37', 'PubchemFP143', 'PubchemFP145', 'PubchemFP146', 'PubchemFP150', 'PubchemFP152', 'PubchemFP153', 'PubchemFP157', 'PubchemFP159', 'PubchemFP160', 'PubchemFP180', 'PubchemFP181', 'PubchemFP186', 'PubchemFP187', 'PubchemFP188', 'PubchemFP192', 'PubchemFP193', 'PubchemFP199', 'PubchemFP256', 'PubchemFP258', 'PubchemFP259', 'PubchemFP261', 'PubchemFP287', 'PubchemFP293', 'PubchemFP294', 'PubchemFP299', 'PubchemFP300', 'PubchemFP305', 'PubchemFP308', 'PubchemFP336', 'PubchemFP338', 'PubchemFP341', 'PubchemFP342', 'PubchemFP345', 'PubchemFP346', 'PubchemFP353', 'PubchemFP357', 'PubchemFP358', 'PubchemFP362', 'PubchemFP364', 'PubchemFP365', 'PubchemFP366', 'PubchemFP368', 'PubchemFP372', 'PubchemFP373', 'PubchemFP374', 'PubchemFP375', 'PubchemFP376', 'PubchemFP377', 'PubchemFP378', 'PubchemFP379', 'PubchemFP380', 'PubchemFP381', 'PubchemFP382', 'PubchemFP383', 'PubchemFP385', 'PubchemFP386', 'PubchemFP387', 'PubchemFP389', 'PubchemFP391', 'PubchemFP392', 'PubchemFP393', 'PubchemFP396', 'PubchemFP403', 'PubchemFP405', 'PubchemFP406', 'PubchemFP412', 'PubchemFP414', 'PubchemFP417', 'PubchemFP418', 'PubchemFP420', 'PubchemFP422', 'PubchemFP427', 'PubchemFP431', 'PubchemFP435', 'PubchemFP437', 'PubchemFP438', 'PubchemFP439', 'PubchemFP440', 'PubchemFP442', 'PubchemFP443', 'PubchemFP445', 'PubchemFP447', 'PubchemFP449', 'PubchemFP450', 'PubchemFP451', 'PubchemFP452', 'PubchemFP453', 'PubchemFP457', 'PubchemFP459', 'PubchemFP460', 'PubchemFP461', 'PubchemFP465', 'PubchemFP467', 'PubchemFP472', 'PubchemFP476', 'PubchemFP477', 'PubchemFP482', 'PubchemFP483', 'PubchemFP484', 'PubchemFP485', 'PubchemFP487', 'PubchemFP491', 'PubchemFP493', 'PubchemFP495', 'PubchemFP497', 'PubchemFP498', 'PubchemFP499', 'PubchemFP500', 'PubchemFP501', 'PubchemFP502', 'PubchemFP503', 'PubchemFP504', 'PubchemFP506', 'PubchemFP507', 'PubchemFP515', 'PubchemFP519', 'PubchemFP521', 'PubchemFP523', 'PubchemFP528', 'PubchemFP530', 'PubchemFP531', 'PubchemFP532', 'PubchemFP535', 'PubchemFP536', 'PubchemFP538', 'PubchemFP539', 'PubchemFP540', 'PubchemFP541', 'PubchemFP542', 'PubchemFP543', 'PubchemFP545', 'PubchemFP546', 'PubchemFP547', 'PubchemFP548', 'PubchemFP550', 'PubchemFP553', 'PubchemFP555', 'PubchemFP560', 'PubchemFP565', 'PubchemFP566', 'PubchemFP567', 'PubchemFP569', 'PubchemFP572', 'PubchemFP573', 'PubchemFP574', 'PubchemFP576', 'PubchemFP577', 'PubchemFP579', 'PubchemFP580', 'PubchemFP585', 'PubchemFP586', 'PubchemFP589', 'PubchemFP591', 'PubchemFP593', 'PubchemFP594', 'PubchemFP596', 'PubchemFP597', 'PubchemFP598', 'PubchemFP600', 'PubchemFP601', 'PubchemFP602', 'PubchemFP604', 'PubchemFP606', 'PubchemFP611', 'PubchemFP614', 'PubchemFP615', 'PubchemFP616', 'PubchemFP617', 'PubchemFP619', 'PubchemFP621', 'PubchemFP623', 'PubchemFP624', 'PubchemFP626', 'PubchemFP636', 'PubchemFP637', 'PubchemFP638', 'PubchemFP641', 'PubchemFP643', 'PubchemFP644', 'PubchemFP645', 'PubchemFP646', 'PubchemFP647', 'PubchemFP650', 'PubchemFP651', 'PubchemFP654', 'PubchemFP655', 'PubchemFP657', 'PubchemFP659', 'PubchemFP662', 'PubchemFP665', 'PubchemFP666', 'PubchemFP667', 'PubchemFP671', 'PubchemFP672', 'PubchemFP673', 'PubchemFP674', 'PubchemFP680', 'PubchemFP682', 'PubchemFP684', 'PubchemFP685', 'PubchemFP686', 'PubchemFP689', 'PubchemFP691', 'PubchemFP692', 'PubchemFP693', 'PubchemFP695', 'PubchemFP696', 'PubchemFP697', 'PubchemFP698', 'PubchemFP699', 'PubchemFP702', 'PubchemFP704', 'PubchemFP712', 'PubchemFP713', 'PubchemFP714', 'PubchemFP716', 'PubchemFP734', 'PubchemFP735', 'PubchemFP755', 'PubchemFP758', 'PubchemFP776', 'PubchemFP777', 'PubchemFP779', 'PubchemFP797', 'PubchemFP798', 'PubchemFP818', 'PubchemFP821']\n",
        "\n",
        "# Filter out the columns using the list of column names\n",
        "#filtered_df = X[column_names]\n",
        "\n",
        "# Alternatively, you can use the .loc accessor to filter the columns\n",
        "filtered_df2 = df4.loc[:, column_names]\n",
        "\n",
        "# Print the filtered dataset\n",
        "filtered_df2"
      ],
      "metadata": {
        "id": "eaGHjN4CYNr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.concat([filtered_df, X_selected], axis=1)\n",
        "merged_df"
      ],
      "metadata": {
        "id": "ujL8SrgAYQH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Training dataset for the model"
      ],
      "metadata": {
        "id": "9G5Os5AeYSqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataset is stored in a DataFrame called 'merged_df'\n",
        "unique_features = merged_df.loc[:, ~merged_df.columns.duplicated()]\n",
        "\n",
        "# Print the DataFrame with only the unique features\n",
        "unique_features\n"
      ],
      "metadata": {
        "id": "EQ6SfpIKYThr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df2 = pd.concat([ X6_selected,filtered_df2], axis=1)\n",
        "merged_df2"
      ],
      "metadata": {
        "id": "gAnazvDOYXu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final testing dataset for the model"
      ],
      "metadata": {
        "id": "syuFYH0TYeYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataset is stored in a DataFrame called 'merged_df'\n",
        "unique_features2 = merged_df2.loc[:, ~merged_df2.columns.duplicated()]\n",
        "\n",
        "# Print the DataFrame with only the unique features\n",
        "unique_features2"
      ],
      "metadata": {
        "id": "CJTrLrtUYb6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data Preparation\n",
        "X = unique_features  # Input features from df5 (assuming the last column is the output column)\n",
        "y = df5.iloc[:, -1]  # Output variable from df5\n",
        "\n",
        "y"
      ],
      "metadata": {
        "id": "izb7VHfYYj0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Dropout\n",
        "!pip install keras-tuner\n",
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "w9_3SXwxYmIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "scaler=StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "9mmnzKozYnZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.2,random_state=42)"
      ],
      "metadata": {
        "id": "5rTcj2ElYrzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "ieWeSn8AYt73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "early_stopping=tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_mse\",\n",
        "    min_delta=0.0001,\n",
        "    patience=20,\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=False,\n",
        "    start_from_epoch=0,\n",
        ")"
      ],
      "metadata": {
        "id": "_KbgOPhzYw79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    counter = 0\n",
        "    lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    for i in range(hp.Int('num_layers', min_value=3, max_value=8)):\n",
        "        if counter == 0:\n",
        "            model.add(Dense(hp.Int('units' + str(i), min_value=300, max_value=800, step=20),\n",
        "                            activation=hp.Choice('activation' + str(i), values=['relu','elu']),\n",
        "                            kernel_initializer=hp.Choice('initializer' + str(i), values=['uniform',\n",
        "                                                                                'glorot_normal', 'glorot_uniform']),\n",
        "                            kernel_regularizer=regularizers.l1_l2(l1=hp.Float('l1', min_value=1e-5, max_value=1e-2, sampling='log'),\n",
        "                                                               l2=hp.Float('l2', min_value=1e-5, max_value=1e-2, sampling='log')),\n",
        "                            input_dim=342))\n",
        "            model.add(Dropout(hp.Choice('dropout' + str(i), values=[0.1, 0.2, 0.3, 0.4])))\n",
        "        else:\n",
        "            model.add(Dense(hp.Int('units' + str(i), min_value=300, max_value=800, step=20),\n",
        "                            activation=hp.Choice('activation' + str(i), values=['relu','elu']),\n",
        "                            kernel_initializer=hp.Choice('initializer' + str(i), values=['uniform',\n",
        "                                                                                'glorot_normal', 'glorot_uniform']),\n",
        "                            kernel_regularizer=regularizers.l1_l2(l1=hp.Float('l1', min_value=1e-5, max_value=1e-2, sampling='log'),\n",
        "                                                               l2=hp.Float('l2', min_value=1e-5, max_value=1e-2, sampling='log'))\n",
        "                            ))\n",
        "            model.add(Dropout(hp.Choice('dropout' + str(i), values=[0.1, 0.2, 0.3, 0.4])))\n",
        "        counter += 1\n",
        "\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    model.compile(optimizer=hp.Choice('optimizer', values=[ 'adam', 'nadam']),\n",
        "                  loss='mean_absolute_error',\n",
        "                  metrics=['mse','mae','mape'])\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "si5hneVtY0mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner=kt.RandomSearch(build_model,\n",
        "                      objective=['val_mse'],\n",
        "                      max_trials=5,seed=29,\n",
        "                      directory='mydire',\n",
        "                      project_name='itadori')\n",
        "\n",
        "tuner.search(X_train,y_train,epochs=5,batch_size=20,validation_data=(X_test,y_test))\n",
        "\n",
        "tuner.get_best_hyperparameters()[0].values\n",
        "\n",
        "model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "\n",
        "history=model.fit(X_train,y_train,epochs=120,initial_epoch=5,validation_data=(X_test,y_test))\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "\n",
        "training_time_seconds = end_time - start_time\n",
        "print(f\"Total training time: {training_time_seconds:.2f} seconds\""
      ],
      "metadata": {
        "id": "cm__WxzoY3eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner=kt.RandomSearch(build_model,\n",
        "                      objective=['val_mse'],\n",
        "                      max_trials=5,seed=10,\n",
        "                      directory='mydire',\n",
        "                      project_name='eren')"
      ],
      "metadata": {
        "id": "cULTr80ZY6im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train,y_train,epochs=5,batch_size=20,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "id": "Ibom4dkmY9K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "id": "1mGRmqolZAFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "TkcMgzqLZMVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "history=model.fit(X_train,y_train,epochs=120,initial_epoch=5,validation_data=(X_test,y_test))\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "\n",
        "training_time_seconds = end_time - start_time\n",
        "print(f\"Total training time: {training_time_seconds:.2f} seconds\")"
      ],
      "metadata": {
        "id": "MOB-W5xRZOoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have defined 'history' earlier\n",
        "\n",
        "# Define custom colors and line styles\n",
        "colors = ['blue', 'red']\n",
        "line_styles = ['-', '-']\n",
        "\n",
        "# Increase the figure size\n",
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "# Plot the training and validation loss with custom colors and line styles\n",
        "plt.plot(history.history['loss'], label='Training Loss', color=colors[0], linestyle=line_styles[0], linewidth=2.5)\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color=colors[1], linestyle=line_styles[1], linewidth=2.5)\n",
        "\n",
        "# Customize the legend\n",
        "plt.legend(fontsize=18)\n",
        "\n",
        "# Add grid lines\n",
        "plt.grid(True, linestyle='--', alpha=0.9)\n",
        "\n",
        "# Set labels and adjust font size\n",
        "plt.xlabel('Epochs', fontsize=30, fontweight='bold')\n",
        "plt.ylabel('Loss', fontsize=30, fontweight='bold')\n",
        "\n",
        "# Increase the font size of the ticks\n",
        "plt.xticks(fontsize=30)\n",
        "plt.yticks(fontsize=30)\n",
        "\n",
        "# Save the plot with increased resolution (dpi)\n",
        "plt.savefig(\"loss.png\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OJuQtwJjZShI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have defined 'history' earlier\n",
        "\n",
        "# Define custom colors and line styles\n",
        "colors = ['blue', 'red']\n",
        "line_styles = ['-', '-']\n",
        "\n",
        "# Increase the figure size\n",
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "# Plot the training and validation MAE with custom colors and line styles\n",
        "plt.plot(history.history['mae'], label='Training MAE', color=colors[0], linestyle=line_styles[0], linewidth=2.5)\n",
        "plt.plot(history.history['val_mae'], label='Validation MAE', color=colors[1], linestyle=line_styles[1], linewidth=2.5)\n",
        "\n",
        "# Customize the legend\n",
        "plt.legend(fontsize=18)\n",
        "\n",
        "# Add grid lines\n",
        "plt.grid(True, linestyle='--', alpha=0.9)\n",
        "\n",
        "# Set labels and adjust font size\n",
        "plt.xlabel('Epochs', fontsize=30, fontweight='bold')\n",
        "plt.ylabel('Mean Absolute Error', fontsize=30, fontweight='bold')\n",
        "\n",
        "# Increase the font size of the ticks\n",
        "plt.xticks(fontsize=30)\n",
        "plt.yticks(fontsize=30)\n",
        "\n",
        "# Save the plot with increased resolution (dpi)\n",
        "plt.savefig(\"MAE.png\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QcoCF4eVZV23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have defined 'history' earlier\n",
        "\n",
        "# Define custom colors and line styles\n",
        "colors = ['blue', 'red']\n",
        "line_styles = ['-', '-']\n",
        "\n",
        "# Increase the figure size\n",
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "# Plot the training and validation MSE with custom colors and line styles\n",
        "plt.plot(history.history['mse'], label='Training MSE', color=colors[0], linestyle=line_styles[0], linewidth=2.5)\n",
        "plt.plot(history.history['val_mse'], label='Validation MSE', color=colors[1], linestyle=line_styles[1], linewidth=2.5)\n",
        "\n",
        "# Customize the legend\n",
        "plt.legend(fontsize=18)\n",
        "\n",
        "# Add grid lines\n",
        "plt.grid(True, linestyle='--', alpha=0.9)\n",
        "\n",
        "# Set labels and adjust font size\n",
        "plt.xlabel('Epochs', fontsize=30, fontweight='bold')\n",
        "plt.ylabel('Mean Squared Error', fontsize=30, fontweight='bold')\n",
        "\n",
        "# Increase the font size of the ticks\n",
        "plt.xticks(fontsize=30)\n",
        "plt.yticks(fontsize=30)\n",
        "\n",
        "# Save the plot as a high-quality image (e.g., PNG, PDF)\n",
        "plt.savefig(\"MSE.png\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OiJ-LhyhZZNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have defined 'history' earlier\n",
        "\n",
        "# Define custom colors and line styles\n",
        "colors = ['blue', 'red']\n",
        "line_styles = ['-', '-']\n",
        "\n",
        "# Increase the figure size\n",
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "# Plot the training and validation MAPE with custom colors and line styles\n",
        "plt.plot(history.history['mape'], label='Training MAPE', color=colors[0], linestyle=line_styles[0], linewidth=2.5)\n",
        "plt.plot(history.history['val_mape'], label='Validation MAPE', color=colors[1], linestyle=line_styles[1], linewidth=2.5)\n",
        "\n",
        "# Customize the legend\n",
        "plt.legend(fontsize=18)\n",
        "\n",
        "# Add grid lines\n",
        "plt.grid(True, linestyle='--', alpha=0.9)\n",
        "\n",
        "# Set labels and adjust font size\n",
        "plt.xlabel('Epochs', fontsize=30, fontweight='bold')\n",
        "plt.ylabel('Mean Absolute Percentage Error', fontsize=30, fontweight='bold')\n",
        "\n",
        "# Increase the font size of the ticks\n",
        "plt.xticks(fontsize=30)\n",
        "plt.yticks(fontsize=30)\n",
        "\n",
        "# Save the plot as a high-quality image (e.g., PNG, PDF)\n",
        "plt.savefig(\"MAPE.png\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UioDYwgnZcbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_test = scaler.transform(unique_features2)"
      ],
      "metadata": {
        "id": "AMUTpvAmZe95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(unique_features2)"
      ],
      "metadata": {
        "id": "ztxtUQo8ZhH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(scaled_test)"
      ],
      "metadata": {
        "id": "WDZlMsFAZjRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe with the predicted values and the first column\n",
        "df_predicted = pd.DataFrame({\"Name\": first_column, \"PIC50 value\": np.squeeze(y_pred)})\n",
        "\n",
        "# Print the dataframe with the predicted values\n",
        "df_predicted"
      ],
      "metadata": {
        "id": "ApjA_HzXZl4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_predicted[\"PIC50 value\"].describe()"
      ],
      "metadata": {
        "id": "nQhur9MwZoQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the threshold value\n",
        "threshold = 0.75 * df_predicted['PIC50 value'].max()\n",
        "\n",
        "# Filter the predicted values based on the threshold\n",
        "df_filtered = df_predicted[df_predicted['PIC50 value'] >= threshold]\n",
        "\n",
        "# Print the filtered dataframe\n",
        "df_filtered"
      ],
      "metadata": {
        "id": "Q9GIo1zdZqtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zip -r third.zip . -i *.png"
      ],
      "metadata": {
        "id": "y49_HOCkZrdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other analysis"
      ],
      "metadata": {
        "id": "YN-pXJnoZ4He"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the first column of the descriptors dataset\n",
        "first_column = df4.iloc[:, 0]\n",
        "first_column"
      ],
      "metadata": {
        "id": "hCgV5E1VZuuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = df4.iloc[:, 1:]\n",
        "df4"
      ],
      "metadata": {
        "id": "jjjUG630aBmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the df5 dataset into training and validation sets\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Model Architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(881,)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Step 4: Model Training\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(X_train_split, y_train_split, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Step 5: Model Evaluation\n",
        "loss = model.evaluate(X_val, y_val)\n",
        "\n",
        "# Step 6: Model Prediction\n",
        "y_pred = model.predict(descriptors_scaled)\n",
        "\n",
        "# Create a dataframe with the predicted values and the first column\n",
        "df_predicted = pd.DataFrame({\"Name\": first_column, \"PIC50 value\": np.squeeze(y_pred)})\n",
        "\n",
        "# Print the dataframe with the predicted values\n",
        "print(df_predicted)"
      ],
      "metadata": {
        "id": "M5vHR2RHaESi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_predicted"
      ],
      "metadata": {
        "id": "1HE5g0DOaHRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_predicted[\"PIC50 value\"].describe()\n"
      ],
      "metadata": {
        "id": "CNt4PSQLaJcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the threshold value\n",
        "threshold = 0.75 * df_predicted['PIC50 value'].max()\n",
        "\n",
        "# Filter the predicted values based on the threshold\n",
        "df_filtered = df_predicted[df_predicted['PIC50 value'] >= threshold]\n",
        "\n",
        "# Print the filtered dataframe\n",
        "df_filtered"
      ],
      "metadata": {
        "id": "3vBT90ZlaLuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered.rename(columns={'Name': 'Cat'}, inplace=True)\n",
        "df_filtered"
      ],
      "metadata": {
        "id": "euJoQsHyaOXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_rows.columns"
      ],
      "metadata": {
        "id": "E6TPLOiNaQ87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered.columns"
      ],
      "metadata": {
        "id": "O-V9ahBRaS4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data splitting"
      ],
      "metadata": {
        "id": "UigZ-TPmaVQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "merged_df = pd.merge(df_rows, df_filtered, on=\"Cat\", how=\"inner\")\n",
        "merged_df"
      ],
      "metadata": {
        "id": "4JbXpzMUaWEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.to_csv('one.csv', index=False)"
      ],
      "metadata": {
        "id": "8FqvLAugaX4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('one_two.csv')\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "HqEsPRnRabKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the values in the 'identity' column\n",
        "df['Mol_ID'] = df['Mol_ID'].apply(lambda x: f'{x}.cdx')\n",
        "\n",
        "# Save the updated DataFrame back to a new CSV file or overwrite the existing one\n",
        "df.to_csv('updated_file.csv', index=False)"
      ],
      "metadata": {
        "id": "dC9-rijoaeAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('updated_file.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "qGp4QfWjaf2f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}